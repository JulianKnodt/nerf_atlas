\section{Limitations}

\paragraph{Bezier Hyperparameters.} While our work is able to accurately capture 3D movement, there are still limitations in what it can capture. Specifically, the selection of number spline points is challenging. If too many points are selected, it can suffer from oscillations, akin to Runge's phenomenon, and this was observed during experimentation. If too few points are selected, the amount of learnable movement is significantly decreased. For the datasets used and those examined in prior work, a single movement is learned, which protects against these issues by selecting between 4-6 control points, but for more complex movement it would be more difficult.

\paragraph{Transient Content.} This work also does not tackle at all changing content in a scene. For example, a temporary effect such as fire, or complex lighting changes beyond shadow movement cannot be accurately captured. This is not a focus of this specific work, but is orthogonal and important when broadly considering dynamic scenes. While this work does not contribute to that, in contrast to prior work, it \textit{prevents} modelling those effects entirely, which is beneficial since another orthogonal component will be more effectively able to learn them.

\paragraph{Reflectance}\label{sec:refl_disc} Another issue with our approach is that our reflectance model may not be clearly motivated. It is able to model more than prior work, by limited linear scaling. This may be seen as a pro and con, in that we may be overfitting to the specific dataset we are testing on, but it may also be broadly viable. In fact, the main motivation for this reflectance is that there are clear view-dependent effects in the dataset which a positional model cannot capture, and a fully view-dependent model cannot generalize to. Ours fits in the middle, capturing just what is necessary, while preventing content from becoming completely dark from other views. Our motivation for this approach was learning a general gamma correction: $A (\text{RGB})^\gamma$, but found that learning gamma even in the limited range $[0.5,1.5]$ failed due to instability. Thus, we only retained the linear term, and found this to still be better than either extreme. We can think of this as akin to a diffuse BSDF, which has an explicit term for diffusion $V\cdot L$, where in our case L is fixed but unknown. In addition, our limitation of $A\in[0.5,1]$ can be considered an implicit bias on the existence of global illumination, in that no particle can be fully black. Hopefully, this sufficiently motivates the extensions to prior work's reflectance models.

\section*{Future Work}

One large next step in neural rendering is to encode dynamic models on top of highly-efficient models, such as using a Plenoxel~\cite{yu2021plenoxels}, Instant Neural Graphics Primitives~\cite{mueller2022instant} or another sparse structure, to allow for rapid training of dynamic scenes. Our voxel implementation does not utilize sparsity as much as possible, nor does it use some of the techniques such as hash-encoding in these works, partially to demonstrate the efficacy of our approach on its own two feet. To the author's knowledge, there is no real-time construction of 3D scenes since there did not exist a classical approach to reliably reconstruct movement. Bezier splines fill in this gap, and only require a fixed number of parameters, allowing for efficient rendering and training without requiring a costly MLP evaluation. If this follows the trend of scene reconstruction, it may be multiple orders of magnitude faster to reconstruct dynamic scenes, without any loss in quality, and we hope that this work gets adopted for this purpose.

In addition, long-term movement in reconstruction has not yet shown to be plausible, but Bezier splines are extendable by turning them into poly-bezier splines or adding more control points. It is not immediately clear how to enable efficient reconstruction over long sequences, but this gives an analytical tool for compositing dynamic scenes with continuity guarantees.

We also hope that future work explores variations on spline formulations, as we select
Bezier splines due to simplicity, numerical stability and ease of evaluation. It may be that other splines might have stronger expressivity for reconstruction or other desirable properties, and thus may be useful in different contexts.

\section*{Conclusion}

In conclusion, we devise a new architecture for $C^0$ continuous interpolation, and show that it works with Dynamic Neural Rendering, both with an MLP and voxels.
Our architecture is able to accurately reconstruct scenes, while providing stronger guarantees using a well-studied tool. Hopefully, this inspires more introduction of classical tools
inside of the differentiable rendering pipeline, so that they

While our work is incremental, requiring very little modification to existing code, since it changes the underlying structure to an analytic form, we expect a large amount of tooling and analytical tools can be built on top of this change, leading to better understanding and analysis of dynamic 3D content.

\iffalse
\section*{Acknowledgements}

Thanks to Elliot Cuzzillo and Seung-Hwan Baek for helping proofread this work.
\fi